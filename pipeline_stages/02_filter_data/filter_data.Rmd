---
title: "Report: Data Filtering"
params:
  input_file: NULL
  output_file: NULL
  max_genes: NULL
  min_genes: NULL
  max_frac_mito: NULL
  doublet_threshold: NULL
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 0.8.5
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
  language_info:
    codemirror_mode:
      name: ipython
      version: 3
    file_extension: .py
    mimetype: text/x-python
    name: python
    nbconvert_exporter: python
    pygments_lexer: ipython3
    version: 3.6.7
---

```{python}
# %load_ext autoreload
# %autoreload 2

import numpy as np
import scanpy.api as sc
import pandas as pd
from pylab import subplots
import os.path
import sys
from matplotlib import pyplot as plt
import sklearn.metrics as skm
sys.path.append("lib")
from jupytertools import *
setwd()
```

```{python}
mito_genes = pd.read_csv("tables/mitochondrial_genes.tsv", sep="\t")["Gene name"].values
biomart = pd.read_csv("tables/biomart.tsv", sep="\t")
ribo_genes = pd.read_csv("tables/ribosomal_genes.tsv", sep="\t", comment="#")["Gene name"].values
```

```{python}
# MAX_GENES = 6000
# MIN_GENES = 500
# MAX_MITO = 0.15
# DOUBLET_DETECTION = True
MAX_GENES = r.params['max_genes']
MIN_GENES = r.params['min_genes']
MAX_MITO = r.params['max_frac_mito']
DOUBLET_THRES = r.params['doublet_threshold']
INPUT_FILE = r.params['input_file']
OUTPUT_FILE = r.params['output_file']
```

```{python read-data}
adata = sc.read_h5ad(INPUT_FILE)
```

```{python}
print(adata)
```

```{python}
# very rough pre-filtering (for completely unfiltered datasets)
sc.pp.filter_cells(adata, min_genes=10)
print(adata.shape)
```

```{python}
tmp_mito = [g for g in mito_genes if g in adata.var_names]
adata.obs['percent_mito'] = np.sum(
    adata[:, tmp_mito].X, axis=1) / np.sum(adata.X, axis=1)
# add the total counts per cell as observations-annotation to adata
adata.obs['n_counts'] = adata.X.sum(axis=1)
adata.obs['n_genes'] = (adata.X != 0).sum(axis=1)
adata.obs['rk_n_genes'] = adata.obs['n_genes'].rank(ascending=False, method="first")
adata.obs['rk_percent_mito'] = adata.obs['percent_mito'].rank(ascending=True, method="first")
```

# Quality Metrics
## Library size and number of detected genes.

```{python}
assert adata.var_names.is_unique
```

```{python}
sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],
             jitter=0.4, multi_panel=True)

```

## Top 20 genes

```{python}
sc.pl.highest_expr_genes(adata, n_top=20, show=True)
```

## Ratio of counts to number of mitochondrial genes

```{python}
sc.pl.scatter(adata, x='n_counts', y='percent_mito', color='samples')
sc.pl.scatter(adata, x='n_counts', y='n_genes', color='samples')
```

```{python}
ax = sc.pl.scatter(adata, x='rk_n_genes', y='n_genes', color='samples', show=False, legend_loc="none")
ax.hlines([MIN_GENES, MAX_GENES], xmin=0, xmax=np.max(adata.obs["rk_n_genes"]))
plt.show()
```

```{python}
ax = sc.pl.scatter(adata, x='rk_percent_mito', y='percent_mito', color='samples', show=False, legend_loc="none")
ax.hlines([MAX_MITO], xmin=0, xmax=np.max(adata.obs["rk_percent_mito"]))
plt.show()
```


# Apply filtering by quality metrics

```{python}
print(adata.shape)
```

```{python}
sc.pp.filter_cells(adata, min_genes=MIN_GENES)
print(adata.shape[0])
```

```{python}
sc.pp.filter_cells(adata, max_genes=MAX_GENES)
print(adata.shape[0])
```

```{python}
adata = adata[adata.obs['percent_mito'] < MAX_MITO, :]
print(adata.shape[0])
```

```{python}
sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],
             jitter=0.4, multi_panel=True)

```

```{python}
# exclude ribosomal and mitochondrial genes
adata = adata[:, ~adata.var_names.isin(np.append(mito_genes, ribo_genes))]
print(adata.shape)
```

```{python}
sc.pl.scatter(adata, x='n_counts', y='percent_mito', color='samples')
sc.pl.scatter(adata, x='n_counts', y='n_genes', color='samples')
```


# Doublet detection

```{python fit-doubletdecon}
import scrublet as scr
adata.obs["doublet_score"] = np.nan
samples = np.unique(adata.obs["samples"])
```

```{python}
if DOUBLET_THRES < 1: 
    for s in samples:
        print("## working on sample {}".format(s))
        mask = adata.obs["samples"] == s
        adata_sub = adata[mask, :].copy()
        scrub = scr.Scrublet(adata_sub.X)
        scores, doublets = scrub.scrub_doublets()

        # visualize
        scrub.plot_histogram()
        adata_sub.obs["is_doublet"] = scores > DOUBLET_THRES
        sc.pp.normalize_per_cell(adata_sub, counts_per_cell_after=1e4)
        sc.pp.log1p(adata_sub)
        sc.pp.filter_genes(adata_sub, min_cells=1)
        sc.tl.pca(adata_sub)
        sc.pp.neighbors(adata_sub, n_neighbors=10, n_pcs=40)
        sc.tl.umap(adata_sub)
        sc.pl.umap(adata_sub, color="is_doublet")

        # store result in global adata
        adata.obs.loc[mask, "doublet_score"] = scores
        print("\n\n")
```

```{python}
adata.obs["is_doublet"] = adata.obs["doublet_score"] > DOUBLET_THRES
```

### Normalize (for visualization only, we will save the raw counts!)

```{python normalize}
# sc.pp.filter_genes(adata, min_cells=1)
adata_vis = adata.copy()
sc.pp.normalize_per_cell(adata_vis, counts_per_cell_after=1e4)
sc.pp.log1p(adata_vis)
sc.pp.filter_genes(adata_vis, min_cells=1)
```

### visualize doublets and remove them

```{python vis-doubletdecon}
sc.tl.pca(adata_vis, svd_solver='arpack')
sc.pp.neighbors(adata_vis, n_neighbors=10, n_pcs=40)
sc.tl.umap(adata_vis)
sc.pl.umap(adata_vis, color=["is_doublet"])
sc.pl.umap(adata_vis, color=["samples"])
```

```{python}
print(adata.shape)
adata = adata[~adata.obs['is_doublet'], :]
adata_vis = adata_vis[~adata_vis.obs['is_doublet'], :]
print(adata.shape)
```

## visualize confounders

```{python pca}
sc.pp.filter_genes(adata_vis, min_cells=1)
sc.tl.pca(adata_vis, svd_solver='arpack')
```

```{python umap}
sc.pp.neighbors(adata_vis, n_neighbors=10, n_pcs=40)
sc.tl.umap(adata_vis)
```

```{python}
sc.pl.umap(adata_vis, color=["n_genes", "n_counts", "percent_mito", "samples", "patient", "origin"], ncols=2)
```

# Leiden clustering and silhouette score

```{python louvain-clustering}
sc.tl.leiden(adata_vis)
```

```{python}
sc.pl.umap(adata_vis, color='leiden')
```

```{python}
print(skm.silhouette_score(adata_vis.X, adata_vis.obs["leiden"], sample_size=2000))
```

# save result
```{python write-results}
adata.write(OUTPUT_FILE, compression="lzf")
adata.write_csvs(os.path.dirname(OUTPUT_FILE))
```
