---
params:
  input_file: NULL
  output_file: NULL
  max_genes: NULL
  min_genes: NULL
  max_frac_mito: NULL
  doublet_detection: NULL
jupyter:
  jupytext_format_version: '1.0'
  kernelspec:
    display_name: Python [conda env:single_cell_integration]
    language: python
    name: conda-env-single_cell_integration-py
  language_info:
    codemirror_mode:
      name: ipython
      version: 3
    file_extension: .py
    mimetype: text/x-python
    name: python
    nbconvert_exporter: python
    pygments_lexer: ipython3
    version: 3.6.6
---


```{python}
# %load_ext autoreload
# %autoreload 2

import numpy as np
import scanpy.api as sc
import pandas as pd
from plotnine import *
from pylab import subplots
import os.path
import sys
sys.path.append("../lib")
from jupytertools import *
import sklearn.metrics as skm
```

```{python}
mito_genes = pd.read_csv("tables/mitochondrial_genes.tsv", sep="\t")["Gene stable ID"].values
biomart = pd.read_csv("tables/biomart.tsv", sep="\t")
ribo_genes = pd.read_csv("tables/ribosomal_genes.tsv", sep="\t", comment="#")["Gene stable ID"].values
```

```{python}
# MAX_GENES = 6000
# MIN_GENES = 500
# MAX_MITO = 0.15
# DOUBLET_DETECTION = True
MAX_GENES = r.params['max_genes']
MIN_GENES = r.params['min_genes']
MAX_MITO = r.params['max_frac_mito']
DOUBLET_DETECTION = r.params['doublet_detection']
INPUT_FILE = r.params['input_file']
OUTPUT_FILE = r.params['output_file']
```

```{python}
adata = sc.read_h5ad(INPUT_FILE)
```

```{python}
adata
```

```{python}
# very rough pre-filtering (for completely unfiltered datasets)
sc.pp.filter_cells(adata, min_genes=10)
adata.shape
```

```{python}
tmp_mito = [g for g in mito_genes if g in adata.var_names]
adata.obs['percent_mito'] = np.sum(
    adata[:, tmp_mito].X, axis=1) / np.sum(adata.X, axis=1)
# add the total counts per cell as observations-annotation to adata
adata.obs['n_counts'] = adata.X.sum(axis=1)
adata.obs['n_genes'] = (adata.X != 0).sum(axis=1)
adata.obs['rk_n_genes'] = adata.obs['n_genes'].rank(ascending=False, method="dense")
adata.obs['rk_percent_mito'] = adata.obs['percent_mito'].rank(ascending=True, method="dense")
```

## Library size and number of detected genes.

```{python}
adata.var_names.is_unique
```

```{python}
sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],
             jitter=0.4, multi_panel=True)

```

## Top 20 genes

```{python}
sc.pl.highest_expr_genes(adata, n_top=20, show=False, annot_col="gene_symbols")
```

## Ratio of counts to number of mitochondrial genes

```{python}
sc.pl.scatter(adata, x='n_counts', y='percent_mito', color='sample')
sc.pl.scatter(adata, x='n_counts', y='n_genes', color='sample')
```

```{python}
(ggplot(adata.obs, aes(x='rk_n_genes', y='n_genes', color='sample')) +
   geom_point() +
   geom_hline(yintercept=MIN_GENES) +
   geom_hline(yintercept=MAX_GENES))
```

```{python}
(ggplot(adata.obs, aes(x='rk_percent_mito', y='percent_mito', color='sample')) +
   geom_point() +
   geom_hline(yintercept=MAX_MITO))
```


## Actually do the filtering

```{python}
adata.shape
```

```{python}
sc.pp.filter_cells(adata, min_genes=MIN_GENES)
print(adata.shape[0])
```

```{python}
sc.pp.filter_cells(adata, max_genes=MAX_GENES)
print(adata.shape[0])
```

```{python}
adata = adata[adata.obs['percent_mito'] < MAX_MITO, :]
print(adata.shape[0])
```

```{python}
sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],
             jitter=0.4, multi_panel=True)

```

```{python}
# exclude ribosomal and mitochondrial genes
adata = adata[:, ~adata.var_names.isin(np.append(mito_genes, ribo_genes))]
print(adata.shape)
```

```{python}
sc.pl.scatter(adata, x='n_counts', y='percent_mito', color='sample')
sc.pl.scatter(adata, x='n_counts', y='n_genes', color='sample')
```


## doublet detection

```{python}
if DOUBLET_DETECTION:
    import doubletdetection
    import time
    clf = doubletdetection.BoostClassifier(n_iters=30)
    start = time.time()
    doublets = clf.fit(adata.X).predict(p_thresh=1e-7, voter_thresh=0.8)
    end = time.time()
    print('Time elapsed: {:.2f} seconds, {:.2f}sec/iteration, for {} iterations'.format(end-start, (end-start) / clf.n_iters, clf.n_iters))
```

```{python doubletdecon}
if DOUBLET_DETECTION:
    adata.obs["doublets"] = np.array(["yes" if x else "no" for x in doublets])
    f = doubletdetection.plot.convergence(clf)
```

### Normalize while keeping the raw data

```{python}
sc.pp.filter_genes(adata, min_cells=1)
adata.raw = sc.pp.log1p(adata, copy=True)
adata_raw = adata.copy()
```

```{python normalize}
sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)
sc.pp.log1p(adata)
```

### visualize doublets and remove them

```{python}
if DOUBLET_DETECTION:
    sc.tl.pca(adata, svd_solver='arpack')
    sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)
    sc.tl.umap(adata)
    sc.pl.umap(adata, color=["doublets"])
```

```{python}
if DOUBLET_DETECTION:
    print(adata.shape)
    adata = adata[adata.obs['doublets'] == "no", :]
    print(adata.shape)
```

## Confounders


## cell cycle

```{python}
cell_cycle_regev = pd.read_csv("tables/cell_cycle_regev.tsv", sep="\t")
cell_cycle_regev = cell_cycle_regev.join(biomart.set_index("HGNC symbol"), on=["hgnc_symbol"], how="inner")\
                        [["Gene stable ID", "phase"]].\
                        drop_duplicates()
```

```{python cell-cycle-score}
sc.tl.score_genes_cell_cycle(adata,
                             s_genes = cell_cycle_regev.loc[cell_cycle_regev["phase"] == "S","Gene stable ID"].values,
                             g2m_genes = cell_cycle_regev.loc[cell_cycle_regev["phase"] == "M","Gene stable ID"].values)
```

```{python}
cc_genes = cell_cycle_regev.loc[cell_cycle_regev["Gene stable ID"].isin(adata.var_names), "Gene stable ID"]
adata_cc_genes = adata[:, cc_genes]
sc.tl.pca(adata_cc_genes)
sc.pl.pca_scatter(adata_cc_genes, color=['phase'])
```

## Visualizations

```{python pca}
sc.tl.pca(adata, svd_solver='arpack')
```

```{python}
sc.pl.pca(adata, color=["n_genes", "n_counts", "percent_mito", "phase", "sample", "patient", "origin"], ncols=2)
```

```{python umap}
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)
sc.tl.umap(adata)
```

```{python}
sc.pl.umap(adata, color=["n_genes", "n_counts", "percent_mito", "phase", "sample", "patient", "origin"], ncols=2)
```

## Remove confounders
### Cell cycle

```{python regress-out-cell-cycle}
sc.pp.regress_out(adata, ['S_score', 'G2M_score'])
sc.pp.scale(adata)
```

```{python}
cc_genes = cell_cycle_regev.loc[cell_cycle_regev["Gene stable ID"].isin(adata.var_names), "Gene stable ID"]
adata_cc_genes = adata[:, cc_genes]
sc.tl.pca(adata_cc_genes)
sc.pl.pca_scatter(adata_cc_genes, color=['phase'])
```

```{python}
sc.tl.pca(adata, svd_solver='arpack')
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)
sc.tl.umap(adata)
```

```{python}
sc.pl.umap(adata, color=["n_genes", "n_counts", "percent_mito", "phase", "sample", "patient", "origin"], ncols=2)
```

## visualize marker genes
We use marker genes from MCP counter to preliminarly identify cell types in the dataset.
The score is very basic, it's the mean sum of all marker genes.

```{python}
mcp_sig = pd.read_csv("tables/mcp_counter_signatures.txt", sep="\t")
mcp_ensembl = mcp_sig.set_index("HUGO symbols").join(biomart.set_index("HGNC symbol"), how="inner")[["Cell population", "Gene stable ID"]]
```

```{python}
cell_types = mcp_ensembl["Cell population"].unique()
for cell_type in cell_types:
    markers = mcp_ensembl.loc[mcp_ensembl["Cell population"] == cell_type, "Gene stable ID"].values
    markers_in_adata = [m for m in markers if m in adata.var_names]
    print("{}: Ignored {}/{} genes because they are not in var_names".format(cell_type,
                    len(markers)-len(markers_in_adata), len(markers)))
    adata.obs[cell_type] = np.log1p(np.sum(adata.X[:,adata.var_names.isin(markers_in_adata)], axis=1)/len(markers_in_adata))

scores = adata.obs[[ct for ct in cell_types if ct in adata.obs.columns]]
adata.obs["cell_type"] = scores.idxmax(axis="columns")

```

```{python}
sc.pl.umap(adata, color=["cell_type"])
```

```{python}
sc.pl.umap(adata, color=[ct for ct in cell_types if ct in adata.obs.columns], ncols=2)
```

## Louvain clustering and silhouette score

```{python louvain-clustering}
sc.tl.louvain(adata)
```

```{python}
sc.pl.umap(adata, color='louvain')
```

```{python}
skm.silhouette_score(adata.X, adata.obs["louvain"], sample_size=2000)
```

## save result
```{python write-results}
adata.write(OUTPUT_FILE, compression="lzf")
adata.write_csvs(os.path.dirname(OUTPUT_FILE))
```
